# test_crawler_quick.py
"""
38ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ í¬ë¡¤ëŸ¬ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸

í¬ë¡¤ëŸ¬ê°€ ì œëŒ€ë¡œ ìž‘ë™í•˜ëŠ”ì§€ ë¹ ë¥´ê²Œ í™•ì¸
"""

import sys
import io

# Windows ì½˜ì†” ì¸ì½”ë”© ì„¤ì •
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

from crawler_38com import ThirtyEightComCrawler

def test_connection():
    """ì—°ê²° í…ŒìŠ¤íŠ¸"""
    print("="*60)
    print("Test 1: ì—°ê²° í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    crawler = ThirtyEightComCrawler()
    
    url = f"{crawler.REPORT_LIST_URL}research_sec.html"
    html = crawler._fetch(url)
    
    if html:
        print(f"âœ… ì—°ê²° ì„±ê³µ")
        print(f"ðŸ“„ HTML í¬ê¸°: {len(html):,} bytes")
        return True
    else:
        print(f"âŒ ì—°ê²° ì‹¤íŒ¨")
        return False

def test_link_extraction():
    """ë§í¬ ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*60)
    print("Test 2: ë§í¬ ì¶”ì¶œ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    crawler = ThirtyEightComCrawler()
    
    # ì‹¤ì œ ì ‘ê·¼ ê°€ëŠ¥í•œ URL ì‹œë„
    test_urls = [
        "http://www.38.co.kr/html/news/?m=kosdaq&nkey=report",
        "http://www.38.co.kr/html/fund/",
        f"{crawler.REPORT_LIST_URL}research_sec.html",
    ]
    
    html = None
    url = None
    
    for test_url in test_urls:
        print(f"ì‹œë„ ì¤‘: {test_url}")
        html = crawler._fetch(test_url)
        if html and len(html) > 1000:
            url = test_url
            print(f"âœ… ì ‘ê·¼ ì„±ê³µ: {url}\n")
            break
    
    if not html:
        print("âŒ ëª¨ë“  URL ì ‘ê·¼ ì‹¤íŒ¨")
        return False
    
    links = crawler._extract_report_links(html)
    
    print(f"âœ… {len(links)}ê°œ ë§í¬ ë°œê²¬")
    
    if links:
        print("\nìƒ˜í”Œ ë§í¬ (ìµœëŒ€ 5ê°œ):")
        for i, link in enumerate(links[:5], 1):
            print(f"  {i}. {link}")
        return True
    else:
        print("âš ï¸  ë§í¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        print("analyze_38com.pyë¥¼ ì‹¤í–‰í•˜ì—¬ HTML êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì„¸ìš”.")
        return False

def test_detail_extraction():
    """ìƒì„¸ ì •ë³´ ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
    print("\n" + "="*60)
    print("Test 3: ìƒì„¸ ì •ë³´ ì¶”ì¶œ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    # ìƒ˜í”Œ URL ìž…ë ¥
    print("\nìƒì„¸ íŽ˜ì´ì§€ URLì„ ìž…ë ¥í•˜ì„¸ìš”.")
    print("(ì—”í„°ë§Œ ì¹˜ë©´ ì´ í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤)")
    
    url = input("URL: ").strip()
    
    if not url:
        print("â­ï¸  í…ŒìŠ¤íŠ¸ ê±´ë„ˆëœ€")
        return True
    
    crawler = ThirtyEightComCrawler()
    report = crawler._crawl_report_detail(url)
    
    if report:
        print("\nâœ… ì¶”ì¶œ ì„±ê³µ!\n")
        print(f"ì œëª©: {report.title}")
        print(f"ì¢…ëª©: {report.stock_name} ({report.stock_code})")
        print(f"ì• ë„ë¦¬ìŠ¤íŠ¸: {report.analyst_name} ({report.firm})")
        print(f"ë‚ ì§œ: {report.published_date.strftime('%Y-%m-%d')}")
        
        if report.investment_opinion:
            print(f"ì˜ê²¬: {report.investment_opinion}")
        
        if report.target_price:
            print(f"ëª©í‘œê°€: {report.target_price}")
        
        return True
    else:
        print("\nâŒ ì¶”ì¶œ ì‹¤íŒ¨")
        print("analyze_38com.pyë¥¼ ì‹¤í–‰í•˜ì—¬ HTML êµ¬ì¡°ë¥¼ ë¶„ì„í•˜ì„¸ìš”.")
        return False

def test_full_crawl():
    """ì „ì²´ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸ (ì ì€ ê°œìˆ˜)"""
    print("\n" + "="*60)
    print("Test 4: ì „ì²´ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    print("\nâš ï¸  ì´ í…ŒìŠ¤íŠ¸ëŠ” ì‹¤ì œë¡œ í¬ë¡¤ë§ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
    print("ê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ", end='')
    
    choice = input().strip().lower()
    
    if choice != 'y':
        print("â­ï¸  í…ŒìŠ¤íŠ¸ ê±´ë„ˆëœ€")
        return True
    
    crawler = ThirtyEightComCrawler(delay=2.0)
    
    print("\nìµœê·¼ 1ì¼, ìµœëŒ€ 5ê°œ ë³´ê³ ì„œ ìˆ˜ì§‘ ì‹œìž‘...")
    
    reports = crawler.crawl_recent_reports(days=1, max_reports=5)
    
    print(f"\nâœ… {len(reports)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ\n")
    
    if reports:
        for i, report in enumerate(reports, 1):
            print(f"{i}. {report.stock_name} - {report.title[:50]}")
        
        # ì €ìž¥
        crawler.save_to_json(reports, 'test_reports.json')
        print("\nðŸ’¾ ì €ìž¥ ì™„ë£Œ: test_reports.json")
        
        return True
    else:
        print("âš ï¸  ë³´ê³ ì„œë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return False

def run_all_tests():
    """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    
    print("ðŸ§ª 38ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ì‹œìž‘\n")
    
    results = []
    
    # Test 1
    results.append(("ì—°ê²° í…ŒìŠ¤íŠ¸", test_connection()))
    
    if not results[-1][1]:
        print("\nâŒ ì—°ê²° ì‹¤íŒ¨. í…ŒìŠ¤íŠ¸ ì¤‘ë‹¨.")
        return
    
    # Test 2
    results.append(("ë§í¬ ì¶”ì¶œ", test_link_extraction()))
    
    if not results[-1][1]:
        print("\nâš ï¸  ë§í¬ ì¶”ì¶œ ì‹¤íŒ¨. HTML êµ¬ì¡° ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        print("analyze_38com.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    
    # Test 3
    results.append(("ìƒì„¸ ì¶”ì¶œ", test_detail_extraction()))
    
    # Test 4
    if results[1][1]:  # ë§í¬ ì¶”ì¶œ ì„±ê³µ ì‹œì—ë§Œ
        results.append(("ì „ì²´ í¬ë¡¤ë§", test_full_crawl()))
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "="*60)
    print("ðŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("="*60)
    
    for test_name, passed in results:
        status = "âœ… í†µê³¼" if passed else "âŒ ì‹¤íŒ¨"
        print(f"{test_name}: {status}")
    
    total = len(results)
    passed = sum(1 for _, p in results if p)
    
    print(f"\nì´ {total}ê°œ ì¤‘ {passed}ê°œ í†µê³¼ ({passed/total*100:.0f}%)")
    
    if passed == total:
        print("\nðŸŽ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! í¬ë¡¤ëŸ¬ê°€ ì •ìƒ ìž‘ë™í•©ë‹ˆë‹¤.")
    else:
        print("\nâš ï¸  ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. í¬ë¡¤ëŸ¬ ìˆ˜ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    if len(sys.argv) > 1:
        # ê°œë³„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        test_num = sys.argv[1]
        
        if test_num == '1':
            test_connection()
        elif test_num == '2':
            test_link_extraction()
        elif test_num == '3':
            test_detail_extraction()
        elif test_num == '4':
            test_full_crawl()
        else:
            print("ì‚¬ìš©ë²•: python test_crawler_quick.py [1-4]")
    else:
        # ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        run_all_tests()

if __name__ == "__main__":
    main()

