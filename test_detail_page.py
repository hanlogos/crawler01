# test_detail_page.py
"""ìƒì„¸ í˜ì´ì§€ ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""

import sys
import io

# Windows ì½˜ì†” ì¸ì½”ë”© ì„¤ì •
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

from crawler_38com import ThirtyEightComCrawler
from bs4 import BeautifulSoup

def test_detail_extraction():
    """ìƒì„¸ í˜ì´ì§€ ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
    
    print("="*60)
    print("ìƒì„¸ í˜ì´ì§€ ì¶”ì¶œ í…ŒìŠ¤íŠ¸")
    print("="*60)
    print()
    
    crawler = ThirtyEightComCrawler()
    
    # í…ŒìŠ¤íŠ¸ URL
    test_url = "http://www.38.co.kr/html/news/?o=v&m=kosdaq&key=report&no=1879932&page=1"
    
    print(f"í…ŒìŠ¤íŠ¸ URL: {test_url}\n")
    
    # 1. HTML ê°€ì ¸ì˜¤ê¸°
    print("1. HTML ê°€ì ¸ì˜¤ê¸°...")
    html = crawler._fetch(test_url)
    
    if not html:
        print("âŒ HTML ì¡°íšŒ ì‹¤íŒ¨")
        return
    
    print(f"âœ… HTML í¬ê¸°: {len(html):,} bytes\n")
    
    # HTML ì €ì¥ (ë¶„ì„ìš©)
    with open('38com_detail_test.html', 'w', encoding='utf-8') as f:
        f.write(html)
    print("ğŸ’¾ ì €ì¥: 38com_detail_test.html\n")
    
    # 2. ìƒì„¸ ì •ë³´ ì¶”ì¶œ
    print("2. ìƒì„¸ ì •ë³´ ì¶”ì¶œ...")
    report = crawler._crawl_report_detail(test_url)
    
    if report:
        print("\nâœ… ì¶”ì¶œ ì„±ê³µ!\n")
        print(f"ì œëª©: {report.title}")
        print(f"ì¢…ëª©: {report.stock_name} ({report.stock_code})")
        print(f"ì• ë„ë¦¬ìŠ¤íŠ¸: {report.analyst_name} ({report.firm})")
        print(f"ë‚ ì§œ: {report.published_date.strftime('%Y-%m-%d')}")
        print(f"URL: {report.source_url}")
        
        if report.investment_opinion:
            print(f"ì˜ê²¬: {report.investment_opinion}")
        
        if report.target_price:
            print(f"ëª©í‘œê°€: {report.target_price}")
    else:
        print("\nâŒ ì¶”ì¶œ ì‹¤íŒ¨")
        print("\nHTML êµ¬ì¡° ë¶„ì„ ì¤‘...\n")
        
        # HTML êµ¬ì¡° ë¶„ì„
        soup = BeautifulSoup(html, 'html.parser')
        
        # ì œëª© ì°¾ê¸°
        print("ì œëª© í›„ë³´:")
        for tag in ['h1', 'h2', 'h3', 'title']:
            elements = soup.find_all(tag)
            for el in elements[:3]:
                text = el.get_text(strip=True)
                if text and len(text) > 5:
                    print(f"  <{tag}>: {text[:80]}")
        
        print("\nì• ë„ë¦¬ìŠ¤íŠ¸ í›„ë³´:")
        for div in soup.find_all(['div', 'span', 'td']):
            text = div.get_text(strip=True)
            if 'ì¦ê¶Œ' in text and len(text) < 100:
                print(f"  {text[:80]}")
                break
        
        print("\në‚ ì§œ í›„ë³´:")
        import re
        date_pattern = r'20\d{2}[./-]\d{1,2}[./-]\d{1,2}'
        for div in soup.find_all(['div', 'span', 'td']):
            text = div.get_text(strip=True)
            if re.search(date_pattern, text):
                print(f"  {text[:80]}")
                break

if __name__ == "__main__":
    test_detail_extraction()

