# test_adaptive_crawler.py
"""
ëŒ€ì‘í˜• í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸

ì‚¬ì „ í…ŒìŠ¤íŠ¸, ì°¨ë‹¨ ê°ì§€, ë™ì  ì¡°ì ˆ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
"""

import sys
import io

# Windows ì½˜ì†” ì¸ì½”ë”© ì„¤ì •
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

from adaptive_crawler import AdaptiveCrawler, SiteProfile
from crawler_38com import ThirtyEightComCrawler

def test_adaptive_crawler():
    """ëŒ€ì‘í˜• í¬ë¡¤ëŸ¬ ê¸°ë³¸ í…ŒìŠ¤íŠ¸"""
    
    print("="*60)
    print("ëŒ€ì‘í˜• í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸")
    print("="*60)
    print()
    
    # ì‚¬ì´íŠ¸ í”„ë¡œí•„ ìƒì„±
    profile = SiteProfile(
        domain="www.38.co.kr",
        base_delay=3.0,
        min_delay=1.0,
        max_delay=10.0
    )
    
    # ëŒ€ì‘í˜• í¬ë¡¤ëŸ¬ ìƒì„±
    crawler = AdaptiveCrawler(profile)
    
    # í…ŒìŠ¤íŠ¸ URL
    test_url = "http://www.38.co.kr/html/fund/"
    
    print(f"í…ŒìŠ¤íŠ¸ URL: {test_url}\n")
    
    # 1. ì‚¬ì „ í…ŒìŠ¤íŠ¸
    print("1. ì‚¬ì „ í…ŒìŠ¤íŠ¸ ì‹¤í–‰...")
    success, message = crawler.pre_test(test_url, test_requests=3)
    
    if success:
        print(f"âœ… ì‚¬ì „ í…ŒìŠ¤íŠ¸ ì„±ê³µ: {message}\n")
    else:
        print(f"âŒ ì‚¬ì „ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {message}\n")
        return
    
    # 2. ì‹¤ì œ ìš”ì²­ í…ŒìŠ¤íŠ¸
    print("2. ì‹¤ì œ ìš”ì²­ í…ŒìŠ¤íŠ¸...")
    response = crawler.fetch(test_url)
    
    if response:
        print(f"âœ… ìš”ì²­ ì„±ê³µ: {len(response.text):,} bytes\n")
    else:
        print("âŒ ìš”ì²­ ì‹¤íŒ¨\n")
        return
    
    # 3. ìƒíƒœ í™•ì¸
    print("3. í¬ë¡¤ëŸ¬ ìƒíƒœ:")
    status = crawler.get_status()
    for key, value in status.items():
        print(f"   {key}: {value}")
    print()
    
    # 4. í”„ë¡œí•„ ì €ì¥
    crawler.save_profile()
    print("ğŸ’¾ í”„ë¡œí•„ ì €ì¥ ì™„ë£Œ\n")

def test_integrated_crawler():
    """í†µí•© í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ (ëŒ€ì‘í˜• í¬ë¡¤ëŸ¬ í¬í•¨)"""
    
    print("="*60)
    print("í†µí•© í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ (ëŒ€ì‘í˜• í¬ë¡¤ëŸ¬ í™œì„±í™”)")
    print("="*60)
    print()
    
    # ëŒ€ì‘í˜• í¬ë¡¤ëŸ¬ í™œì„±í™”í•˜ì—¬ í¬ë¡¤ëŸ¬ ìƒì„±
    crawler = ThirtyEightComCrawler(
        delay=3.0,
        use_adaptive=True,
        site_domain="www.38.co.kr"
    )
    
    # ì‚¬ì „ í…ŒìŠ¤íŠ¸
    print("ì‚¬ì „ ì—°ê²° í…ŒìŠ¤íŠ¸...")
    success, message = crawler.pre_test_connection()
    
    if success:
        print(f"âœ… ì‚¬ì „ í…ŒìŠ¤íŠ¸ ì„±ê³µ: {message}\n")
    else:
        print(f"âš ï¸  ì‚¬ì „ í…ŒìŠ¤íŠ¸ ê²½ê³ : {message}\n")
    
    # ì‹¤ì œ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸
    print("ë§í¬ ì¶”ì¶œ í…ŒìŠ¤íŠ¸...")
    test_url = "http://www.38.co.kr/html/news/?m=kosdaq&nkey=report"
    html = crawler._fetch(test_url)
    
    if html:
        links = crawler._extract_report_links(html)
        print(f"âœ… {len(links)}ê°œ ë§í¬ ë°œê²¬\n")
        
        # ìƒíƒœ í™•ì¸
        status = crawler.get_crawler_status()
        if status:
            print("í¬ë¡¤ëŸ¬ ìƒíƒœ:")
            for key, value in status.items():
                print(f"   {key}: {value}")
    else:
        print("âŒ HTML ì¡°íšŒ ì‹¤íŒ¨\n")

def test_block_detection():
    """ì°¨ë‹¨ ê°ì§€ í…ŒìŠ¤íŠ¸"""
    
    print("="*60)
    print("ì°¨ë‹¨ ê°ì§€ í…ŒìŠ¤íŠ¸")
    print("="*60)
    print()
    
    profile = SiteProfile(domain="test.com")
    crawler = AdaptiveCrawler(profile)
    
    # ì •ìƒ ìš”ì²­
    print("1. ì •ìƒ ìš”ì²­ í…ŒìŠ¤íŠ¸...")
    response = crawler.fetch("http://www.38.co.kr/html/fund/")
    
    if response:
        print("âœ… ì •ìƒ ìš”ì²­ ì„±ê³µ\n")
    else:
        print("âŒ ìš”ì²­ ì‹¤íŒ¨\n")
    
    # ìƒíƒœ í™•ì¸
    status = crawler.get_status()
    print("í¬ë¡¤ëŸ¬ ìƒíƒœ:")
    print(f"   ì„±ê³µë¥ : {status['success_rate']:.1%}")
    print(f"   í‰ê·  ì‘ë‹µ ì‹œê°„: {status['avg_response_time']:.2f}ì´ˆ")
    print(f"   í˜„ì¬ ì§€ì—° ì‹œê°„: {status['current_delay']:.2f}ì´ˆ")
    print(f"   ê±´ê°• ìƒíƒœ: {'âœ… ì–‘í˜¸' if status['is_healthy'] else 'âš ï¸ ì£¼ì˜'}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    print("ğŸ§ª ëŒ€ì‘í˜• í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸ ì‹œì‘\n")
    
    try:
        # í…ŒìŠ¤íŠ¸ 1: ëŒ€ì‘í˜• í¬ë¡¤ëŸ¬ ê¸°ë³¸ í…ŒìŠ¤íŠ¸
        test_adaptive_crawler()
        
        print("\n" + "="*60 + "\n")
        
        # í…ŒìŠ¤íŠ¸ 2: í†µí•© í¬ë¡¤ëŸ¬ í…ŒìŠ¤íŠ¸
        test_integrated_crawler()
        
        print("\n" + "="*60 + "\n")
        
        # í…ŒìŠ¤íŠ¸ 3: ì°¨ë‹¨ ê°ì§€ í…ŒìŠ¤íŠ¸
        test_block_detection()
        
        print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()


