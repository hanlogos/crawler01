# integrated_research_crawler.py
"""
í†µí•© ë¦¬ì„œì¹˜ í¬ë¡¤ëŸ¬

í•œê²½ ì»¨ì„¼ì„œìŠ¤ + ë„¤ì´ë²„ ê¸ˆìœµ ë¦¬ì„œì¹˜ë¥¼ í†µí•©í•˜ì—¬ ìˆ˜ì§‘

ê³„ì•½:
- ì…ë ¥: stock_name (str, ì¢…ëª©ëª…), stock_code (Optional[str], ì¢…ëª©ì½”ë“œ), days (int, ìµœê·¼ Nì¼)
- ì¶œë ¥: Dict with keys: 'reports', 'scores', 'consensus'
- ì˜ˆì™¸: ValueError (ì˜ëª»ëœ íŒŒë¼ë¯¸í„°), ImportError (ì˜ì¡´ì„± ëª¨ë“ˆ ì—†ìŒ), requests.RequestException (ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜)
"""

import logging
from typing import List, Dict, Optional
from datetime import datetime, timedelta
import os

try:
    from crawler_hankyung_consensus import HankyungConsensusCrawler
    HANKYUNG_AVAILABLE = True
except ImportError:
    HANKYUNG_AVAILABLE = False
    HankyungConsensusCrawler = None

try:
    from crawler_naver_finance_research import NaverFinanceResearchCrawler
    NAVER_AVAILABLE = True
except ImportError:
    NAVER_AVAILABLE = False
    NaverFinanceResearchCrawler = None

try:
    from analyst_report_scorer import AnalystReportScorer
    SCORER_AVAILABLE = True
except ImportError:
    SCORER_AVAILABLE = False
    AnalystReportScorer = None

class IntegratedResearchCrawler:
    """
    í†µí•© ë¦¬ì„œì¹˜ í¬ë¡¤ëŸ¬
    
    í•œê²½ ì»¨ì„¼ì„œìŠ¤ì™€ ë„¤ì´ë²„ ê¸ˆìœµ ë¦¬ì„œì¹˜ë¥¼ í†µí•©í•˜ì—¬ ìˆ˜ì§‘í•˜ê³  ì ìˆ˜í™”
    
    ì‚¬ìš©ë²•:
        crawler = IntegratedResearchCrawler()
        reports = crawler.collect_stock_reports("ì‚¼ì„±ì „ì", "005930", days=7)
        
        # ì ìˆ˜í™” í¬í•¨
        scored_reports = crawler.collect_and_score("ì‚¼ì„±ì „ì", "005930", days=7)
    """
    
    def __init__(
        self,
        use_hankyung: bool = True,
        use_naver: bool = True,
        download_pdf: bool = False,
        download_dir: str = "AnalystReports"
    ):
        """
        ì´ˆê¸°í™”
        
        Args:
            use_hankyung: í•œê²½ ì»¨ì„¼ì„œìŠ¤ ì‚¬ìš© ì—¬ë¶€
            use_naver: ë„¤ì´ë²„ ê¸ˆìœµ ì‚¬ìš© ì—¬ë¶€
            download_pdf: PDF ë‹¤ìš´ë¡œë“œ ì—¬ë¶€
            download_dir: ë‹¤ìš´ë¡œë“œ ë””ë ‰í† ë¦¬
        """
        self.logger = logging.getLogger(__name__)
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s'
        )
        
        self.use_hankyung = use_hankyung and HANKYUNG_AVAILABLE
        self.use_naver = use_naver and NAVER_AVAILABLE
        self.download_pdf = download_pdf
        self.download_dir = download_dir
        
        # í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
        self.hankyung_crawler = None
        if self.use_hankyung:
            try:
                self.hankyung_crawler = HankyungConsensusCrawler()
                self.logger.info("âœ… í•œê²½ ì»¨ì„¼ì„œìŠ¤ í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                self.logger.warning(f"âš ï¸  í•œê²½ ì»¨ì„¼ì„œìŠ¤ í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.use_hankyung = False
        
        self.naver_crawler = None
        if self.use_naver:
            try:
                self.naver_crawler = NaverFinanceResearchCrawler(
                    download_dir=download_dir
                )
                self.logger.info("âœ… ë„¤ì´ë²„ ê¸ˆìœµ ë¦¬ì„œì¹˜ í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                self.logger.warning(f"âš ï¸  ë„¤ì´ë²„ ê¸ˆìœµ ë¦¬ì„œì¹˜ í¬ë¡¤ëŸ¬ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.use_naver = False
        
        # ì ìˆ˜í™” ì‹œìŠ¤í…œ
        self.scorer = None
        if SCORER_AVAILABLE:
            try:
                self.scorer = AnalystReportScorer()
                self.logger.info("âœ… ë¦¬í¬íŠ¸ ì ìˆ˜í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                self.logger.warning(f"âš ï¸  ì ìˆ˜í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def collect_stock_reports(
        self,
        stock_name: str,
        stock_code: Optional[str] = None,
        days: int = 7,
        max_reports: int = 100
    ) -> List[Dict]:
        """
        ì¢…ëª© ë¦¬í¬íŠ¸ ìˆ˜ì§‘ (í†µí•©)
        
        Args:
            stock_name: ì¢…ëª©ëª… (ì˜ˆ: "ì‚¼ì„±ì „ì")
            stock_code: ì¢…ëª©ì½”ë“œ (Noneì´ë©´ ìë™ ê²€ìƒ‰, ê¸°ë³¸ê°’: None)
            days: ìµœê·¼ Nì¼ (ê¸°ë³¸ê°’: 7)
            max_reports: ìµœëŒ€ ìˆ˜ì§‘ ê°œìˆ˜ (ê¸°ë³¸ê°’: 100)
            
        Returns:
            List[Dict]: ë¦¬í¬íŠ¸ ë©”íƒ€ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (dict í˜•ì‹)
                - ê° dictëŠ” ReportMetadata.to_dict() ê²°ê³¼ì™€ ë™ì¼í•œ êµ¬ì¡°
            
        Raises:
            ValueError: ì˜ëª»ëœ stock_name ë˜ëŠ” days < 0
            ImportError: í•„ìš”í•œ í¬ë¡¤ëŸ¬ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŒ
            requests.RequestException: ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë˜ëŠ” í˜ì´ì§€ ì¡°íšŒ ì‹¤íŒ¨
            
        ê³„ì•½:
        - ì…ë ¥: stock_nameì€ ë¹„ì–´ìˆì§€ ì•Šì€ ë¬¸ìì—´, daysëŠ” ì–‘ìˆ˜
        - ì¶œë ¥: Dict ë¦¬ìŠ¤íŠ¸ (ë¹ˆ ë¦¬ìŠ¤íŠ¸ ê°€ëŠ¥, ì¤‘ë³µ ì œê±°ë¨)
        - ì˜ˆì™¸: ValueError (ì˜ëª»ëœ íŒŒë¼ë¯¸í„°), ImportError (ì˜ì¡´ì„± ì—†ìŒ), RequestException (ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜)
        """
        
        # ì…ë ¥ ê²€ì¦
        if not stock_name or not isinstance(stock_name, str):
            raise ValueError(f"stock_name must be a non-empty string, got {stock_name}")
        if days < 0:
            raise ValueError(f"days must be non-negative, got {days}")
        if max_reports < 0:
            raise ValueError(f"max_reports must be non-negative, got {max_reports}")
        
        self.logger.info(f"ğŸ” í†µí•© ë¦¬ì„œì¹˜ ìˆ˜ì§‘ ì‹œì‘: {stock_name} ({stock_code})")
        
        all_reports = []
        
        # 1. ë„¤ì´ë²„ ê¸ˆìœµ ìˆ˜ì§‘ (ìš°ì„ ìˆœìœ„ 1)
        if self.use_naver and self.naver_crawler:
            try:
                self.logger.info("ğŸ“Š ë„¤ì´ë²„ ê¸ˆìœµ ë¦¬ì„œì¹˜ ìˆ˜ì§‘ ì¤‘...")
                naver_reports = self.naver_crawler.search_by_stock(
                    stock_name=stock_name,
                    stock_code=stock_code,
                    days=days,
                    max_reports=max_reports,
                    download_pdf=self.download_pdf
                )
                
                # dictë¡œ ë³€í™˜
                for report in naver_reports:
                    report_dict = report.to_dict() if hasattr(report, 'to_dict') else report
                    all_reports.append(report_dict)
                
                self.logger.info(f"âœ… ë„¤ì´ë²„ ê¸ˆìœµ: {len(naver_reports)}ê°œ ìˆ˜ì§‘")
                
            except Exception as e:
                self.logger.error(f"âŒ ë„¤ì´ë²„ ê¸ˆìœµ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        # 2. í•œê²½ ì»¨ì„¼ì„œìŠ¤ ìˆ˜ì§‘ (ë³´ì¡°)
        if self.use_hankyung and self.hankyung_crawler:
            try:
                self.logger.info("ğŸ“Š í•œê²½ ì»¨ì„¼ì„œìŠ¤ ìˆ˜ì§‘ ì¤‘...")
                hankyung_reports = self.hankyung_crawler.search_by_stock(
                    stock_name=stock_name,
                    days=days,
                    max_reports=max_reports
                )
                
                # dictë¡œ ë³€í™˜
                for report in hankyung_reports:
                    report_dict = report.to_dict() if hasattr(report, 'to_dict') else report
                    # ì¤‘ë³µ ì œê±° (URL ê¸°ë°˜)
                    if not any(r.get('source_url') == report_dict.get('source_url') for r in all_reports):
                        all_reports.append(report_dict)
                
                self.logger.info(f"âœ… í•œê²½ ì»¨ì„¼ì„œìŠ¤: {len(hankyung_reports)}ê°œ ìˆ˜ì§‘")
                
            except Exception as e:
                self.logger.error(f"âŒ í•œê²½ ì»¨ì„¼ì„œìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        # ì¤‘ë³µ ì œê±° (report_id ê¸°ë°˜)
        seen_ids = set()
        unique_reports = []
        for report in all_reports:
            report_id = report.get('report_id', '')
            if report_id and report_id not in seen_ids:
                seen_ids.add(report_id)
                unique_reports.append(report)
        
        self.logger.info(f"ğŸ‰ í†µí•© ìˆ˜ì§‘ ì™„ë£Œ: {len(unique_reports)}ê°œ (ì¤‘ë³µ ì œê±° í›„)")
        
        return unique_reports
    
    def collect_and_score(
        self,
        stock_name: str,
        stock_code: Optional[str] = None,
        days: int = 7,
        max_reports: int = 100
    ) -> Dict:
        """
        ë¦¬í¬íŠ¸ ìˆ˜ì§‘ ë° ì ìˆ˜í™”
        
        Returns:
            {
                'reports': List[Dict],  # ì›ë³¸ ë¦¬í¬íŠ¸
                'scores': List[ReportScore],  # ì ìˆ˜í™”ëœ ë¦¬í¬íŠ¸
                'consensus': Dict  # ì»¨ì„¼ì„œìŠ¤ ì •ë³´
            }
        """
        
        # ë¦¬í¬íŠ¸ ìˆ˜ì§‘
        reports = self.collect_stock_reports(
            stock_name=stock_name,
            stock_code=stock_code,
            days=days,
            max_reports=max_reports
        )
        
        if not reports:
            return {
                'reports': [],
                'scores': [],
                'consensus': {}
            }
        
        # ì ìˆ˜í™”
        scores = []
        if self.scorer:
            try:
                scores = self.scorer.score_multiple_reports(reports)
                self.logger.info(f"âœ… ì ìˆ˜í™” ì™„ë£Œ: {len(scores)}ê°œ")
            except Exception as e:
                self.logger.error(f"âŒ ì ìˆ˜í™” ì‹¤íŒ¨: {e}")
        
        # ì»¨ì„¼ì„œìŠ¤ ê³„ì‚°
        consensus = {}
        if self.scorer and stock_code:
            try:
                consensus = self.scorer.get_stock_consensus_score(stock_code, days=days)
            except Exception as e:
                self.logger.error(f"âŒ ì»¨ì„¼ì„œìŠ¤ ê³„ì‚° ì‹¤íŒ¨: {e}")
        
        return {
            'reports': reports,
            'scores': [s.to_dict() if hasattr(s, 'to_dict') else s for s in scores],
            'consensus': consensus
        }
    
    def save_summary(
        self,
        stock_name: str,
        stock_code: str,
        result: Dict,
        filename: Optional[str] = None
    ):
        """ìˆ˜ì§‘ ê²°ê³¼ ìš”ì•½ ì €ì¥"""
        
        if not filename:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"research_summary_{stock_name}_{stock_code}_{timestamp}.json"
        
        summary = {
            'stock_name': stock_name,
            'stock_code': stock_code,
            'collected_at': datetime.now().isoformat(),
            'reports': result.get('reports', []),
            'scores': result.get('scores', []),
            'consensus': result.get('consensus', {})
        }
        
        import json
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        self.logger.info(f"ğŸ’¾ ìš”ì•½ ì €ì¥ ì™„ë£Œ: {filename}")

# ============================================================
# ì‚¬ìš© ì˜ˆì œ
# ============================================================

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    crawler = IntegratedResearchCrawler(
        use_hankyung=True,
        use_naver=True,
        download_pdf=True
    )
    
    print("ğŸš€ í†µí•© ë¦¬ì„œì¹˜ í¬ë¡¤ëŸ¬ ì‹œì‘\n")
    
    # ì‚¼ì„±ì „ì ë¦¬í¬íŠ¸ ìˆ˜ì§‘ ë° ì ìˆ˜í™”
    result = crawler.collect_and_score(
        stock_name="ì‚¼ì„±ì „ì",
        stock_code="005930",
        days=7,
        max_reports=50
    )
    
    print(f"\nğŸ“Š ìˆ˜ì§‘ ê²°ê³¼:")
    print(f"  ë¦¬í¬íŠ¸ ìˆ˜: {len(result['reports'])}ê°œ")
    print(f"  ì ìˆ˜í™”ëœ ë¦¬í¬íŠ¸: {len(result['scores'])}ê°œ")
    
    if result['consensus']:
        consensus = result['consensus']
        print(f"\nğŸ“ˆ ì»¨ì„¼ì„œìŠ¤:")
        print(f"  ì´ ì ìˆ˜: {consensus.get('total_score', 0):.2f}")
        print(f"  í‰ê·  ì ìˆ˜: {consensus.get('average_score', 0):.2f}")
        print(f"  BUY: {consensus.get('buy_count', 0)}ê°œ")
        print(f"  HOLD: {consensus.get('hold_count', 0)}ê°œ")
        print(f"  SELL: {consensus.get('sell_count', 0)}ê°œ")
    
    # ìš”ì•½ ì €ì¥
    crawler.save_summary("ì‚¼ì„±ì „ì", "005930", result)
    
    print("\nâœ… ì™„ë£Œ!")

if __name__ == "__main__":
    main()

