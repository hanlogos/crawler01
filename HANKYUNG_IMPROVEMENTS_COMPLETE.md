# í•œê²½ ì»¨ì„¼ì„œìŠ¤ í¬ë¡¤ëŸ¬ ê°œì„  ì™„ë£Œ ë³´ê³ ì„œ

## âœ… ì™„ë£Œëœ ê°œì„  ì‚¬í•­

### 1. ë¦¬í¬íŠ¸ ëª©ë¡ í…Œì´ë¸”ì—ì„œ ë©”íƒ€ë°ì´í„° ì§ì ‘ ì¶”ì¶œ âœ…

**ê°œì„  ë‚´ìš©**:
- `_extract_report_list()` ë©”ì„œë“œ ì¶”ê°€: ëª©ë¡ í˜ì´ì§€ì—ì„œ ë°”ë¡œ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
- í…Œì´ë¸” í—¤ë” ìë™ ì¸ì‹: ë‚ ì§œ, ì¦ê¶Œì‚¬, ì• ë„ë¦¬ìŠ¤íŠ¸, ì˜ê²¬, ëª©í‘œê°€ ì»¬ëŸ¼ ìë™ ê°ì§€
- ë°ì´í„° í–‰ íŒŒì‹±: ê° ë¦¬í¬íŠ¸ í–‰ì—ì„œ ì •ë³´ ì¶”ì¶œ
- ë¦¬ìŠ¤íŠ¸ êµ¬ì¡° ì§€ì›: í…Œì´ë¸”ì´ ì—†ëŠ” ê²½ìš° ë¦¬ìŠ¤íŠ¸ êµ¬ì¡°ì—ì„œë„ ì¶”ì¶œ

**ì¶”ì¶œ ê°€ëŠ¥í•œ ì •ë³´**:
- ì¦ê¶Œì‚¬ëª… (ì˜ˆ: NHíˆ¬ìì¦ê¶Œ)
- ì• ë„ë¦¬ìŠ¤íŠ¸ ì´ë¦„
- íˆ¬ìì˜ê²¬ (BUY/HOLD/SELL)
- ëª©í‘œì£¼ê°€
- ë¦¬í¬íŠ¸ ë‚ ì§œ
- ë¦¬í¬íŠ¸ URL
- PDF URL (ìˆëŠ” ê²½ìš°)
- ì¢…ëª©ëª… ë° ì¢…ëª©ì½”ë“œ

**íš¨ê³¼**:
- ìƒì„¸ í˜ì´ì§€ ë°©ë¬¸ ì—†ì´ ëª©ë¡ í˜ì´ì§€ì—ì„œ ë°”ë¡œ ì •ë³´ ìˆ˜ì§‘ ê°€ëŠ¥
- í¬ë¡¤ë§ ì†ë„ í–¥ìƒ (ìƒì„¸ í˜ì´ì§€ ë°©ë¬¸ ê°ì†Œ)
- ì„œë²„ ë¶€í•˜ ê°ì†Œ

### 2. PDF ë§í¬ ì¶”ì¶œ ê°•í™” âœ…

**ê°œì„  ë‚´ìš©**:
- `_extract_pdf_url()` ë©”ì„œë“œ ì¶”ê°€: ìƒì„¸ í˜ì´ì§€ì—ì„œ PDF ë§í¬ ì¶”ì¶œ
- ë‹¤ì¤‘ íŒ¨í„´ ì§€ì›:
  1. PDF ë§í¬ ì§ì ‘ ì°¾ê¸° (`.pdf`, `pdf`, `download` í‚¤ì›Œë“œ)
  2. [PDF] ë²„íŠ¼ í…ìŠ¤íŠ¸ë¡œ ì°¾ê¸°
  3. iframe ë‚´ PDF ë§í¬
  4. data-url ì†ì„±ì—ì„œ ì¶”ì¶œ

**íš¨ê³¼**:
- PDF ë‹¤ìš´ë¡œë“œ ë§í¬ ì¶”ì¶œ ì •í™•ë„ í–¥ìƒ
- ë‹¤ì–‘í•œ HTML êµ¬ì¡°ì— ëŒ€ì‘

### 3. ì˜ê²¬ í…ìŠ¤íŠ¸ ì •ê·œí™” ê°œì„  âœ…

**ê°œì„  ë‚´ìš©**:
- `_normalize_opinion()` ë©”ì„œë“œ ì¶”ê°€: ì˜ê²¬ í…ìŠ¤íŠ¸ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ì •ê·œí™”
- ì§€ì› í˜•ì‹:
  - `STRONG_BUY`: ë§¤ìˆ˜(ê°•ë ¥), ê°•ë ¥ë§¤ìˆ˜, ì ê·¹ë§¤ìˆ˜, Strong Buy
  - `BUY`: ë§¤ìˆ˜, Buy, ë¹„ì¤‘í™•ëŒ€
  - `HOLD`: ì¤‘ë¦½, ë³´ìœ , ì‹œì¥ìˆ˜ìµë¥ , Hold, Neutral
  - `SELL`: ë§¤ë„, Sell, ë¹„ì¤‘ì¶•ì†Œ
  - `STRONG_SELL`: ë§¤ë„(ê°•ë ¥), ê°•ë ¥ë§¤ë„, Strong Sell

**íš¨ê³¼**:
- ë‹¤ì–‘í•œ í˜•ì‹ì˜ ì˜ê²¬ í…ìŠ¤íŠ¸ë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ í†µì¼
- ë°ì´í„° ì¼ê´€ì„± í–¥ìƒ

### 4. í—¬í¼ ë©”ì„œë“œ ì¶”ê°€ âœ…

**ì¶”ê°€ëœ ë©”ì„œë“œ**:
- `_parse_date_from_text()`: í…ìŠ¤íŠ¸ì—ì„œ ë‚ ì§œ íŒŒì‹±
- `_extract_price_from_text()`: í…ìŠ¤íŠ¸ì—ì„œ ê°€ê²© ì¶”ì¶œ (1,000ì› ~ 1,000,000,000ì› ë²”ìœ„)
- `_normalize_opinion()`: ì˜ê²¬ í…ìŠ¤íŠ¸ ì •ê·œí™”
- `_extract_pdf_url()`: PDF ë§í¬ ì¶”ì¶œ

## ğŸ“Š ê°œì„  ì „í›„ ë¹„êµ

| í•­ëª© | ê°œì„  ì „ | ê°œì„  í›„ |
|------|---------|---------|
| ë©”íƒ€ë°ì´í„° ì¶”ì¶œ | ìƒì„¸ í˜ì´ì§€ ë°©ë¬¸ í•„ìˆ˜ | ëª©ë¡ í˜ì´ì§€ì—ì„œ ë°”ë¡œ ì¶”ì¶œ ê°€ëŠ¥ |
| í¬ë¡¤ë§ ì†ë„ | ëŠë¦¼ (ëª¨ë“  ë¦¬í¬íŠ¸ ìƒì„¸ ë°©ë¬¸) | ë¹ ë¦„ (ëª©ë¡ì—ì„œ ì •ë³´ ì¶”ì¶œ) |
| PDF ë§í¬ ì¶”ì¶œ | ê¸°ë³¸ íŒ¨í„´ë§Œ | ë‹¤ì¤‘ íŒ¨í„´ ì§€ì› |
| ì˜ê²¬ ì •ê·œí™” | ë¶€ë¶„ ì§€ì› | ì™„ì „ ì§€ì› (5ê°€ì§€ í˜•ì‹) |
| ê°€ê²© ì¶”ì¶œ | ê¸°ë³¸ íŒ¨í„´ | ë²”ìœ„ ê²€ì¦ í¬í•¨ |
| í…Œì´ë¸” íŒŒì‹± | ë§í¬ë§Œ ì¶”ì¶œ | ì „ì²´ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ |

## ğŸ”§ ì‚¬ìš© ë°©ë²•

### ê¸°ë³¸ ì‚¬ìš© (ë³€ê²½ ì—†ìŒ)

```python
from crawler_hankyung_consensus import HankyungConsensusCrawler

crawler = HankyungConsensusCrawler(delay=3.0)

# ìµœê·¼ ë¦¬í¬íŠ¸ ìˆ˜ì§‘
reports = crawler.crawl_recent_reports(days=7, max_reports=50)

# ì¢…ëª©ë³„ ê²€ìƒ‰
reports = crawler.search_by_stock("ì‚¼ì„±ì „ì", days=7, max_reports=50)
```

### ê°œì„ ëœ ê¸°ëŠ¥ í™œìš©

```python
# ëª©ë¡ í˜ì´ì§€ì—ì„œ ë©”íƒ€ë°ì´í„° ì§ì ‘ ì¶”ì¶œ (ë‚´ë¶€ì ìœ¼ë¡œ ìë™ ì‚¬ìš©)
# ë” ë¹ ë¥¸ í¬ë¡¤ë§, ë” ë§ì€ ì •ë³´ ìˆ˜ì§‘

# ì˜ê²¬ ì •ê·œí™” ìë™ ì ìš©
# "ë§¤ìˆ˜" â†’ "BUY", "ë§¤ìˆ˜(ê°•ë ¥)" â†’ "STRONG_BUY"

# PDF ë§í¬ ìë™ ì¶”ì¶œ
# ë¦¬í¬íŠ¸ ìƒì„¸ í˜ì´ì§€ì—ì„œ PDF ë‹¤ìš´ë¡œë“œ ë§í¬ ìë™ ê°ì§€
```

## ğŸ“ ë‹¤ìŒ ë‹¨ê³„ (ì„ íƒ)

### ë„¤ì´ë²„ ê¸ˆìœµ ìë™ ë³´ì™„ ë¡œì§ ì¶”ê°€ (ë¯¸ì™„ë£Œ)

**ê³„íš**:
- í•œê²½ì—ì„œ PDF ì ‘ê·¼ ì‹¤íŒ¨ ì‹œ ë„¤ì´ë²„ ê¸ˆìœµìœ¼ë¡œ ìë™ ì¬ì‹œë„
- `IntegratedResearchCrawler`ì— ì´ë¯¸ ë¶€ë¶„ êµ¬í˜„ë˜ì–´ ìˆìŒ
- í•œê²½ í¬ë¡¤ëŸ¬ì— ì§ì ‘ í†µí•© ê°€ëŠ¥

**êµ¬í˜„ ì˜ˆì‹œ**:
```python
def search_by_stock_with_fallback(
    self,
    stock_name: str,
    days: int = 7,
    max_reports: int = 50
) -> List[ReportMetadata]:
    """í•œê²½ â†’ ë„¤ì´ë²„ ê¸ˆìœµ ìë™ ë³´ì™„"""
    # 1. í•œê²½ì—ì„œ ìˆ˜ì§‘
    reports = self.search_by_stock(stock_name, days, max_reports)
    
    # 2. PDF ì—†ëŠ” ë¦¬í¬íŠ¸ í™•ì¸
    reports_without_pdf = [r for r in reports if not r.pdf_url]
    
    # 3. ë„¤ì´ë²„ ê¸ˆìœµì—ì„œ ë³´ì™„
    if reports_without_pdf:
        from crawler_naver_finance_research import NaverFinanceResearchCrawler
        naver_crawler = NaverFinanceResearchCrawler()
        naver_reports = naver_crawler.search_by_stock(stock_name, days, max_reports)
        
        # 4. ë³‘í•©
        # ...
```

## ğŸ¯ ì£¼ìš” ê°œì„  íš¨ê³¼

1. **í¬ë¡¤ë§ ì†ë„**: ëª©ë¡ í˜ì´ì§€ì—ì„œ ë°”ë¡œ ì •ë³´ ì¶”ì¶œë¡œ ì†ë„ í–¥ìƒ
2. **ì •ë³´ ì™„ì „ì„±**: ëª©ë¡ í˜ì´ì§€ì—ì„œ ë” ë§ì€ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
3. **ì •í™•ë„**: ì˜ê²¬ ì •ê·œí™”, ê°€ê²© ì¶”ì¶œ ì •í™•ë„ í–¥ìƒ
4. **ìœ ì—°ì„±**: ë‹¤ì–‘í•œ HTML êµ¬ì¡°ì— ëŒ€ì‘ ê°€ëŠ¥

## ğŸ“š ì°¸ê³  ë¬¸ì„œ

- `HANKYUNG_CRAWLER_IMPROVEMENTS.md`: ê°œì„  ê³„íš ë¬¸ì„œ
- `crawler_hankyung_consensus.py`: ê°œì„ ëœ í¬ë¡¤ëŸ¬ ì½”ë“œ
- PDF ì°¸ê³  ë‚´ìš©: í•œê²½ ì»¨ì„¼ì„œìŠ¤ ì‚¬ìš© ê°€ì´ë“œ

